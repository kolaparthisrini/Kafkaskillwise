https://www.7-zip.org/
https://share.internxt.com/d/sh/folder/3647eb2ec03b928035b3/c958b723a5d30de54c016c42935b3d757ac4893b8fd5e185b9b87e22d6aa2204
https://github.com/kolaparthisrini

kAFKA
=================
JDK
kafka offset
notepad++
zookeeper 
kafka
jdk
eclipse
7zip
============================
To initiate kafka on local machine,we needd to follow below steps.
1)Download zookeeper server.
2)make necessary modifications in server config files,if necessary
3)start the server and check wwhther server is running on the specified port.
4)Download Kafka server to any drive except downloads folder.
note: dont launch any server from downloads folder.
5)Make necessary changes to kafka config and launch the kafka server parallely with zookeeper.
=============================================Day2==============================
Queue: it is a data structure/storage area which works on principle FIFO.

queues will have only one producer and only 1 consumer at a time.

producer--------->Queue------------>consumer
Topic: it is a data structure/storage area/log file.

Organization producer

Data is money

Consumer is employee.

Topics will have any no of  producers and any number of consumers at a time.


Topic and queues are not databases.It will store your data temporarly.
Broker: means a kafka node/machine.
Cluster/chain/group: Group of machines or servers or terminals or nodes.In kafka,to create a cluster,as per
 the best practices,we need to have atleast 3 nodes.
machines can be at same location or in remote location as well.
Https:it is secure protocol.

Https= Http+SSl  layer

when we say about ssl,we need to focus on security certificates.

certificates are of 2 types.
1)self signed: self signed certs are created by us using java.
2)commercial: commercial certs are provided by vendors like godaddy,verisign,desicert,paypal,paytm,...etc.
Note: In production or realtime,we use only commercial certs.No self signed.
self signed are used for learning purpose.

In this certs,we will have private security keys.
kafka  3rd party GUI tools uses https protocls.

replication:replication means duplicating the messages across network.
Consumer: Anything which receives data is called as consumer
consumer group:group of consumers is called as consumer group
Producer: Anything which emits data is called as producer
producer group:group of producers is called as Producer group.
Vertical scaling:increasing no of cpus and memory
Horizontal scaling:increasing more no of machines to existing cluster.
Autoscaling: all cloud providers supports autoscalingie it can do horizonal or vertically automatically
without manual involvement
Encryption and decrytion rules:

Encryption means converting plain text to cipher text is called as encryption.
reverse is called as decryption.

Once the encryption is done in one machine,decryption cannot be done in another machine.

Apache kafka vs confluence kafka:
Meta data: 
Example: login credentials,ip address,its shape,color....etc.any thing which describes an object can be called as meta data.

Table: dextara
column:uname,pwd -string--8,empid--string--primary key constraint name

Data:alphabets,numbers,symbols,characters,...etcdata will be in meaningless format.
Information:processed data which is meaning full is called as information.
tcp:it is n/w protocol for transfering data from client to server securely.
kafka uses tcp protocol.
policy:  set of rules/guidelinees which are  used to controll resources,their access from secure way.
In kafka,kafka came up with security and retension policies.polices in any technology is written in either 
xml or json or bson.
bson is  more advanced than json.
Ways to install kafka:
1)on premises: https://kafka.apache.org/downloads

Always go with GA(general availabilityie making it public) releases.dont uses canary release or beta releases for production environments.
2)confluence kafka cloud
https://www.confluent.io/lp/confluent-kafka/?utm_medium=sem&utm_source=google&utm_campaign=ch.sem_br.brand_tp.prs_tgt.confluent-brand_mt.xct_rgn.india_lng.eng_dv.all_con.confluent-kafka-general&utm_term=confluent%20kafka&creative=&device=c&placement=&gclid=CjwKCAiAxvGfBhB-EiwAMPakqmw1ZULbyBl-f_mDJMjTskBk-Vi6opVU9Rjhv0_VrGZghG7BjobyOhoCWB0QAvD_BwE

Apache kafka vs confluent kafka?
common things are both will do same work,same componets.

Apache kafka is open source while onfluent kafka is commercial(confluent community license and enterprise license).
apache kafka is for on-premises,but confluent kafka is for cloud.
Confluent provides more no of tools and connectors by default,where in apache kafka additional things are not provided.s

3)docker--on the top of containers ,we can install.
4)VM---virtual machine
5)other cloud providers--AWS,azure,gcp....etc
We can start and stop zookeeper and kafka using bat files also.
============================================================================================
===============================================================================================
Day3
----------
Architectures
workflows
Kafka admin activities from CLI
>>serialization:means saving SBI of an object into temporary storage files is called as Serialization.
Every object will have SBI
S-state
B-behaviour---means its functionality
I-identity-name of the object

when i click on "pause".

deserialization: mean sit is like "resuming" to previous state.
>>>>>>
Dmart--------sales data
     --------Purchases data
	 ---------salary data
	 ---------other data 
	 ----------Transporation data....etc------------------>Data center
	                                                         ----->Audit purpose or knowing the financial statistics...etc

You need to load Producer API,consumer API,Broker API.
================================================
Day4
--------------------
1. List Topics: kafka-topics.bat --list --zookeeper localhost:2181 
2. Describe Topic: kafka-topics.bat --describe --zookeeper localhost:2181 --topic [Topic Name] 
3. Read messages from beginning: kafka-console-consumer.bat --zookeeper localhost:2181 --topic [Topic Name] --from-beginning
kafka-console-consumer.bat --zookeeper localhost:2181 --topic [Topic Name] --from-beginning
Points to remember:
========================
>IN Kafka Every message has key and value.keys are unqiue and messgaes can be same.Offset tool uses hexadecimal format to
push the messages to kafka topic.
>always partitions numbering starts from 0.
>Always when we create a topic by default one partition will be created.always partition number starts with 0.
>It is not a good idea to change your partitions after creating topic
>no of partitions should not be infifnity.
per cluster(min of 3 brokers and max of 50), we can have 2lakhs partitons.
per broker,we can have 4k partitions.
>Unnecessarily dont delete topics.
>There are some known issues in windows os while droping a topic.
>prior to kafka 2.12.0 version,we need to use --zookeeper,in the place of --bootstrap-server.
-------------------
>  by default brokerid wikll be 0.We can modify the broker id from the kafka configuration file ie server.properties file.
>Default port no of kafka is 9092
>broker name will be your hostname,ie computer name by default.
===============
srini,where is my topic created ?i want to see that?
ans)Kafka stores the topic messages on the top of your hardisk in the form of logs.
new Messages will be appended to the end of your log file.
even partitions will be stored on the top of ur machine ie in your topic location.
>>>>>>>>>>When we say a replication/duplicate of 2,then how many brokers shld be there?
ans)2























































------------
Day4
------
Configurations of kafka
about partions
Replications
insyncreplicas
multibroker architectures













